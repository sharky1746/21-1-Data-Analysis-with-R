
# Q1: 
# 임의의 20가구에 대헤 연간 소득 및 오락비 지출을 조사하여 단위는 dollar로 Family.txt에 저장하였다.
# 오락비 지출과 연간소득 관련 여부를 알고 싶은 것이 분석의 목적입니다. 다음 질문에 답하시오.
# 단, 데이터가 "./Data/Family.txt"에 있다고 가정하고, 아래와 같이 데이터를 읽어드린다.
# 그러므로, 여러분도 아래와 같이 데이터를 ./Data directory 밑에 두어야 합니다.
FmlyData = read.table("./Data/Family.txt", header=T)

# Q1-1.[5점] 산점도를 그리고, 시각적으로 판단한 관측치의 선형성을 섦명하시오.
plot(Recreation~Income, data=FmlyData)

# x축 Income이 증가함에 따라, y축 Recreation 지출도 증가하는 것올 보이는
# 관측치의 경향이 있으므로, Income과 Recreation 지출은 양의 선형관계가 있다고 할 수 있다.
# 연간소득이 있어야 오락비 지출이 가능해 오락비 지출과 연간소득은 인과관계인 것 같으나 그렇다고 단정할 수능 없습니다.
# 오락비 지출이 xx일때 연간소득을 추정할 수도 있고, 연간소득이 yy일 때 오락비 지출을 추정할 수도 있어,
plot(Income~Recreation, data=FmlyData) # 가능합니다.


# Q1-2.[5점] 주어진 오락비 지출과 수입 관측치 간 관계를 R 코드를 사용해 linear modeling 하십시오.
lmRslt <- lm(Recreation~Income, data=FmlyData)
summary(lmRslt)

> summary(lmRslt)

Call:
lm(formula = Recreation ~ Income, data = FmlyData)

Residuals:
    Min      1Q  Median      3Q     Max 
-895.09 -347.75  -26.82  368.02  863.70 

Coefficients:
              Estimate Std. Error t value Pr(>|t|)    
(Intercept) -3.726e+02  4.370e+02  -0.853    0.405    
Income       6.957e-02  9.062e-03   7.678 4.38e-07 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 537.2 on 18 degrees of freedom
Multiple R-squared:  0.7661,	Adjusted R-squared:  0.7531 
F-statistic: 58.95 on 1 and 18 DF,  p-value: 4.38e-07


# Q1-3.[30점] Q1-2에서 얻은 결과에서 "회귀모형의 적합성"을 F값의 p-value로 검정하는 이유를 설명하시오.

# 주어진 관측치를 R lm() 함수를 사용해 도출한 단순선형회귀선은 F-값의 p-value 4.38e-07은
# 통상적 유의수준 0.05보다 작으므로 회귀선이 관측치를(혹은 관찰치라고도 함) 유의미하게 섦명하고 있다고 할 수 있다.
# 질문이 있었기에 설명을 추가하자면, t-값, z-값, or F-값이 채택한 유의수준 [0.001, 0.05, etc.] 보다 작으면
# 우리는 대립가설을 채택합니다. 대립가설은 우리가 연구를 통해 증명하고자 하는 가설로서 연구가설이라고도 하고, 
# 대립가설을 우선적으로 설정하면, 대립가설의 여집합이 귀무가설이 됩니다. 이 문제에서 연구가설은 우리가 통계적 방법을 통해 찾아낸
# 회귀선이 관측치를 잘 설명하고 있다는 것입니다. 유의수준보다 F값 p-value가 작으므로 대립가설을(연구가설) 채택하고,
# 즉, 회귀선이 관측치를 잘 설명하고 있다는 결론에 도달합니다. 그러면 회귀선이(회귀모형) 관측치를 잘 설명하고 있다는 의미는?

# 통계를 학습하지 않은 분들은 위 개념적 설명이 이해가 잘 되지 않을 수 있습니다.
# 회귀식을 도출하는 방식은 다양한데, 대표적인 방법이 최소자승법(Least Squared Method)이고,
# 이는 알고 있다고 가정합니다.

# 통계수업은 아니지만 설명을 곁들이기 전, 답안 설명을 위해 용어를 정의합니다.
#	잔차(Residual): 관측치들과 산출될 회귀선과의 거리, Error라고도 함 
#	SST=Sum of Squared Total;총제곱합, 그림에서 보듯이 SST = SSR+SSE 
#	SSR=Sum of Squared Regression; 회귀제곱합, 회귀선으로 설명되는 제곱합
#	SSE=Sum of Squared Error; 잔차제곱합, 회귀선으로 설명되지 않는 제곱합 
# 	MSR=Mean of Squared Regression; 회귀평균제곱
#	MSE=Mean of Squared Error; 잔차평균제곱
# 	
# 개념적으로 이해하려면, 통계적 설명은 Lec06 자료 91페이지 그림과 표를 보십시오. 
# 갖게되는 의문이 왜 F값의 p-value로 회귀식 모형의 적합도를 판단하는가? 하는 질문을 할 수 있습니다.<= 문제임.
# 이는 통계학에서 설명하는 것으로, 본 수업의 범위는 벗어나지만 이해를 돕도록 개념을 설명합니다.
# 요약적으로 말하자면, 회귀분석을 분산분석의 관점으로 해석하는 것입니다. 분산분석의 기본 개념은 이해하고 있는 것으로 간주합니다.

# 분산분석의 관점으로 회귀분석을 보면, 주어진 독립변수 값에 따라 
# 규정된 집단에 속한 종속변수의 평균을 나타내는 회귀선과 집단전체의 평균과의 차이를 [=> SSR]
# 회귀선으로부터 떨어져 있는 잔차와 [=> SSE] 비교하여 통계적으로 유의하게 다른가를 분석하는 것이 됩니다.
# 쉽게 말하면 SSR 대비 SSE가 적으면 회귀선이 관치를 잘 설명하고 있는 겁니다. 회귀선을 잘 설정한 겁니다.

# 그런데, SSR과 SSE는 관측치의 수와(n) 회귀식에서 사용된 독립변수 수에(k) 따라 달라, 직접적 비교는 무의미합니다.
#  (예를들어, n이 증가하면 절대적으로 SSE가 적어도(잔차제곱합이 적어도) SSR은 증가하게 됩니다.)
# 그러므로, 관측치 수와 독립변수 수에 따라 변화하지 않는 [평균제곱]을 구해 비교해야 옳습니다.
# 이것이 MSR과 MSE인데 이는 SSR과 SSE를 각각의 자유도로 나누어 구할 수 있다. 각각의 자유도를 구하는 방법은 설명하지 않는다.
# (통상적으로 평균을 구할 때 평균=관측치의 합/관측치 수로 하짐만, 관측치 수가 엄격히는 [자유도]입니다.)

# 이렇게 구한 MSR을 MSE로 나누면 (MSR/MSE) 개념상으로 회귀선이 전체 평균으로부터 떨어져 있는 정도가,
# (단, 거리가 아닌 거리의 제곱, 제곱합이 크면 당연히 거리의 합도 크므로 개념상 '떨어져 있는 정도'로 표현함)
# 개별 관측치들이 회귀선으로부터 떨어져 있는 정도의 몇 배인가를 나타내는 통계량 값이 되는데, 
# 정의에 의해 F값은 분산의 비율이므로, MSR/MSE가 표본(관측치)으로부터 얻은 분산의 비율이어서 F값이 됩니다.
# 그러므로, 현재 관측치(표본)로부터 구한 F값이 회귀식의 통계적 유의성을 검정값이 되는 것입니다.
# 검정통계량 F값이 클수록(MSR/MSE 값이 클수록) 추정된 회귀식이 관측치를 잘 설명하는데,
# 이를 통계적으로 유의미함을 검정하기 위해 채택한 유의수준과 비교합니다.
# 이러한 회귀모형의 통계적 유의성 검정은 분산분석의 유의성 검정과 동일하다하고, 회귀분석을 분산분석의 관점으로 해석한다 한 이유입니다.

# 예를 들어, 현재 표본으로부터 산출한 F값보다 큰 값이 나올 확률이 채택한 유의수준 0.05 이하인 경우에는
# "2개의 분산이 같다"(분산분석의 귀무가설)는 귀무가설을 기각함으로써,
# 회귀식으로 설명되는 MSR이 회귀식으로 설명되지 않는 MSE보다
# 통계적으로 유의할(통계적으로 의미가 있을) 정도로 크다고 판단하게 된다.

# 또 아래와 같이 생각해 볼 수도 있습니다. F값으로 검정을 한다면 귀무가설과 대립가설이 존재하는데,
# 이 경우 귀무 및 대리가설은 무엇일까?
# F값으로 검정하고자 하는 것은 회귀모형입니다. 회귀모형은(회귀모델이라고 하기도 합니다) 곧 회귀식입니다.
# 그러므로, 아래와 같이 설정할 수 있습니다.

# 귀무가설: Recreation은(Y) Income에(X) 대한 회귀식으로 설명할 수 없다.
# 대립가설: Recreation은(Y) Income에(X) 대한 회귀식으로 설명가능하다.

# 회귀식: Y(Recreation) = -3.726e+02 + 6.957e-02*X(Income)

# 여기서 Y 절편(b0) -3.726e+02는 X가 0일 때 종속변수 값을 의미합니다. 기울기(b1;6.957e-02)는
# 독립변수가 가지고 있는 반응값에 대한 단위 당 영향력을 의미합니다. 기울기가 양의 값을 갖는다면 독립변수 값이 증가할수록
# 종속변수 값이 증가하며 음의 값을 갖는다면 감소하며, 절대값이 클수록 영향이 크다는 것을 의미합니다.

# 이 영향력 역시 유의한지를 검정할 수 있는데, 이를 회귀계수의 검정 혹은 회귀식의 기울기 검정이라고 합니다.
# 기울기 검정은 t-분포를 이용하므로 위 회귀분석 결과에서 t-value 와 이에 대한 p-value 값이 있습니다.
# 회귀계수는 t분포를 따르기 떄문입니다. 회귀계수가 0인가를 확인하는 검정은 해당 독립변수가 종속변수에 영향을 미치는지
# 아닌지 여부를 확인하는 것과 같습니다. 2개 이상의 독립변수가 포함된 모형에서도 사용할 수 있으며, 각 독립변수의
# 독립적인 영향력을 평가합니다.
# 그러므로, 회귀계수에 대한 귀무 및 대립가설은 아래와 같습니다.
# 귀무가설: 기울기(b1) 즉, 회귀계수는 0이다.
# 대립가설: 기울기(b1) 즉, 회귀계수는 0이 아니다.

예를 들어, 데이터가 원모양이면 기울기가 0으로 나타나는데 직선의 형태를 띠고 있지 않다면 분석이 불가능합니다.
왜냐하면, 독립변수 x는 종속변수 y의 원인이라고 할 수 없다.
그러므로, 산포도를 그려 시각적으로 데이터 분포 파악이 필요하고, 
따라서, 회귀계수는, 즉 기울기, 결국 t-test의 평균값 차이와 동잃한 개념으로 회귀계수는 t-test로 유의성 테스트를 합니다.
표본으로부터 추정하는 회귀계수도 확률변수이다. 왜냐하면 서로 다른 표본에서 추정되는 회귀계수 값이 다를 수 있기 때문이다.
그러므로, 추정된 기울기가 0과 통계적으로 다른지가 회귀분석에서 검정해야 한다.
귀무가설: 기울기가 0이다.
대립가설: 기울기가 0이 아니다.

# 그럼므로, 회귀모형(회귀모델 혹은 회귀식) 적합도를 F값에 의해 유의서을 검정하는 것과 회귀계수 유의성을 검정하는 것을
# 혼동하지 말아야 합니다.

# 간혹 여기서 회귀계수가 0인 경우로 이를 설명하기도 하는데, 의미를 이해해야 합니다.
# F값이 0이면 MSR/MSE = 0 이고 0이 되려면 MSR이 0인 경우입니다. MSR이 0이란 말은 dfR은 0이 아니므로
# SSR=0 인 경우인데, SSR이 0이 되려면, 회귀식의 기울기가 0가 되어야 합니다. 그래서 회귀식의 기울기 즉, 회귀계수가 0인
# 경우입니다. 그러나, F값이 0에 가까울수록 회귀모델이 적합하지 않다하고 이야기하는 것은 옳지 않습니다.
# 왜냐하면 Family.txt 데이터에서 기울기는 0에 가깝지만, F값으로 판단할 때는 유의합니다.
# 그래서, 단순히, F값이 0에 가까울수록 회귀모델이 적합하지 않다하고 이야기하는 것은 옳지 않은데,
# 달리 표현하자면, F값은 기울기에 대한 통계량이 아닌 분산에 대한 비율이기 때문입니다.

# 회귀분석에 detail이 아닌 전반적 개념을 잘 이해하고 있는지 묻는 문제였습니다.


# For your reference, please see the following;------------------------------------
# 회귀모형에서 알아두면 좋은 R code.
# R 제공데이터 선언
head(cars, 10)
# 회귀모델 생성
a <- lm(dist~speed, cars)
# 회귀계수 추출
coef(a)
# 예측값 계산
fitted(a)[1:4]
# 잔차계산
residuals(a)[1:4]
# 회귀계수 신뢰구간 계산
confint(a)
# 잔차제곱합 계산
deviance(a)
# x=4 일 때, 예측값 구하기
predict(a, newdata=data.frame(speed=4))
# 예측값의 신뢰구간
predict(a, newdata=data.frame(speed=4), interval="confidence")
# 오차항을 고려한 예측값의 신뢰구간
predict(a, newdata=data.frame(speed=4), interval="prediction")
# 회귀모형 평가
summary(a)
# 잔차 등분산성 검정과
par(mfrow=c(2,2))
# 잔차추출
res <- residual(a)
# 잔차 정규성 검정
shapiro.test(res)
# 잔차 독립성 검정; 더빈왓슨 검정을(Durbin-Watson test) 통해 
# 잔차 독립성을 검정하며 결과값이 2에 가까울수록 잔차에 독립성이 있다고 판단.
# DW 값이 0이면 양의 자기 상관, 4일 때 음의 자기상관이 있어 회귀분석에 부적합하다고 말합니다.
# 역시 p-value로 판단하는데 0.05 유의수준 0.05에서 DW값이 이보다 작으면 독립성을 따르지 않습니다.
귀무가설: 잔차가 독립성이 있다. (=> 잔차끼리 독립성이 있다. 즉, 잔차 간에 자기 상관성이 없다라고 볼 수 있다.)
대립가설: 잔차가 독립성이 없다.

install.packages("lmtest")
library(lmtest)
dwtest(a)





# Q1-4.[10점] 연간 소득이 $65,000인 가구의 평균 오락비 지출을 추정하고, 95% 신뢰 구간을 구하시오.
new_Incm <- data.frame(Income = c(65000))
new_Incm

predict(lmRslt, newdata = new_Incm)
> predict(lmRslt, newdata = new_Incm)
      1 
4149.52

predict(lmRslt, newdata=data.frame(Income=c(65000)), interval="confidence", level = 0.95)
> predict(lmRslt, newdata=data.frame(Income=c(65000)), interval="confidence")
      fit      lwr      upr
1 4149.52 3714.152 4584.888



# Q2:
# 우리가 예제로 많이 사용했던 iris 데이터를 사용합니다. iris에는 150개의 관측치가 있으며,
# Sepal은 꽃받침, Petal은 꽃잎을 말하고, 데이터를 살펴보면 3개의 Species(품종) 있음을 알 수 있습니다.
# 품종 별로 꽃잎 넓이의 차이가 있는지 분석하는 문제입니다.
str(iris)
attach(iris)
# Q2-1. [20점] 품종 별로 꽃잎 넓이의 차이 여부를 분석하기 위해 귀무가설과 대립가설을 설정하시오.
	귀무가설: 세 품종의 꽃잎 넓이 평균에는 차이가 없다.
	대립가설: 적어도 한 품종의 평균은 다르다.
	
# Q2-2. [20점] R 함수를 사용해 분산분석표를 산출하고, 분석분석표에 출현하는 하단의 용어를 설명하시오.
# 분산분석표; 10점, 각 설명 1점.
> result <- aov(Petal.Width ~ Species)
> summary(result)
             Df Sum Sq Mean Sq F value Pr(>F)    
Species       2  80.41   40.21     960 <2e-16 ***
Residuals   147   6.16    0.04                   
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

	a. Df: 자유도
	b. Sum Sq: 제곱합
	c. Mean Sq: 평균제곱합 (Sum Sq/Df)
	d. F Value: F 통계값
	e. Pr(>F): 유의확률
	f. Species: 요인(factor)
	g. Residuals: 잔차
	h. Signif. codes: when variables are statistically significant (변수가 통계적으로 의미가 있을 때)
	j. 독립변수는 무엇인가? Species
	k. 종속변수는 무엇인가? Petal.Width


# Q2-3. [10점] 꽃잎 넓이의 평균이 서로 다른 품종 집단을 제시하고, 꽃잎이 넓은 품종부터 좁은 순으로 품종을 나열하시오.
TukeyHSD(result)

> TukeyHSD(result)
  Tukey multiple comparisons of means
    95% family-wise confidence level

Fit: aov(formula = Petal.Width ~ Species)

$Species
                     diff       lwr       upr p adj
versicolor-setosa    1.08 0.9830903 1.1769097     0
virginica-setosa     1.78 1.6830903 1.8769097     0
virginica-versicolor 0.70 0.6030903 0.7969097     0

# 모두 유의확률이 작으므로 세 품종 모두 유의미하게 다르다는 것을 알 수 있다.
# Verginica > Versicolor > Setosa


detach(iris)